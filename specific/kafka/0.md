The Kafka Consumer origin reads data from a single topic in an Apache Kafka cluster. To use multiple threads to read from multiple topics, use the Kafka Multitopic Consumer.

When the consumer group and topic combination does not have a previously stored offset, the Kafka Consumer origin by default receives messages sent to the topic after the pipeline starts, processing data from all partitions and ignoring any existing messages in the topic.

The Kafka Consumer origin uses the following Kafka configuration properties. The origin ignores user-defined values for these properties:
auto.commit.enable
group.id
zookeeper.connect

This situation happens because of offsets expiration. There are two parameters in kafka controlling this behaviour. First of all it is the "retention.ms" setting of consumer offsets topic. It should be equal to -1 to disable expiration of records inside that topic.

Here the ExpirationTime value makes sense. The Group Coordinator will read only unexpired records at the moment of offsets loading, i.e. now() < ExpirationTime, and these values are returned to client's offset fetch request.

offsets.retention.minutes

ExpirationTime = CommitTime + offsets.retention.minutes

Groups only works with subscription, not with assignment.

The offset commit are only used when you start a consumer or when performing rebalancing.

### Producer performance

Sometimes 99 percentile performance can not be tuned, although turning the average helps with the number

* batch.size
* linger.ms
* max.in.flight.requests.per.connection
* acks

kafka 0.9 performance improvement:
3 ms (99th percentile)
14 ms (99.9th percentile)

Since Kafka 0.10, Kafka messages contain a timestamp. This timestamp can be assigned by the producer, or is assigned by the broker if none is provided. By comparing timestamps in the output topic with timestamps in the input topic, we can measure processing latency.

How long will the producer wait before sending in order to allow more messages to get accumulated in the same batch. Normally the producer will not wait at all, and simply send all the messages that accumulated while the previous send was in progress

If sending is still slow and you are trying to understand what is going on, you will want to check if the send thread is fully utilized through jvisualsm (it is called kafka-producer-network-thread) or keep an eye on average batch size metric. If you find that you canâ€™t fill the buffer fast enough and the sender is idle, you can try adding application threads that share the same producer and increase throughput this way.
