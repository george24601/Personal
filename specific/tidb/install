#!bin/bash

terraform apply -var-file=multi.tfvars

export CLUSTER_NAME=stg2tidb
aws eks --region ap-northeast-1 update-kubeconfig --name ${CLUSTER_NAME}

kubectl apply -f manifests/crd.yaml
kubectl apply -f manifests/local-volume-provisioner.yaml
kubectl apply -f manifests/gp2-storageclass.yaml
kubectl apply -f manifests/tiller-rbac.yaml
helm init --service-account tiller --upgrade --wait

###Is the cluster good now?
helm version

helm install charts/tidb-operator --name tidb-operator --namespace tidb-admin
<<OP

NOTES:
1. Make sure tidb-operator components are running
   kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator
2. Install CRD
   kubectl apply -f https://raw.githubusercontent.com/pingcap/tidb-operator/master/manifests/crd.yaml
   kubectl get customresourcedefinitions
3. Modify tidb-cluster/values.yaml and create a TiDB cluster by installing tidb-cluster charts
   helm install tidb-cluster

OP

#stg1
helm install charts/tidb-cluster --name stg1-tidb-cluster --namespace stg1 --values stg1_tidb_cluster_values.yaml

helm upgrade stg1-tidb-cluster  charts/tidb-cluster --namespace stg1 --values stg1_tidb_cluster_values.yaml


#stg2
helm install charts/tidb-cluster --name stg2-tidb-cluster --namespace stg2 --values stg2_tidb_cluster_values.yaml

kubectl get po -n tidb -lapp.kubernetes.io/component=tidb

kubectl get services -n stg1

kubectl port-forward svc/stg1-tidb-cluster-pd 2379:2379

helm delete --purge tidb-cluster-george


<<EOF
if you only care about the leader count of each store, you can run `./pd-ctl -d store | jq '.stores[] | {tikv: .store.address, leader: .status.leader_count} '`
(a store is corresponding to a TiKV Pod)

To set the leader priority for AZ:
1. label the TiKV nodes by AZ, the Pod will automatically pick up this label then
2. set reject leader scheduler to ensure the leader will not be placed to the target AZ if possible:
`pd-ctl config set label-property reject-leader az <az_name>`
3. note that the new Nodes also need to be labeled

EOF

#Label nodes
for item in $( kubectl get node --output=name);
  do kubectl label "$item" \
  $(kubectl get "$item" --output=json | jq -r -S '.metadata.labels | to_entries | .[] | select (.key | contains ("zone")) | "zone=\(.value)"' 2>/dev/null);
done


