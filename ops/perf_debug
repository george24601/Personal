#!/bin/bash
<<TOP
* Note that `top` has different layouts on centos and os x
* Are there too many users? Load average should be < 0.5 * # of cores
* If `us` is too high, then user processes are consuming much CPU resources, use `top -p $PID`
* If `sy` is too high, what is kernel working on?
* If `wa` is too high, the cpu idle waits for IO too much.
* If `Swap` > 0, are we running out of physical RAM?
* Check if `VIRT` is within your expectation - You should have a basic idea on how much virtual memory a process uses.

ni: high nice value user space process

Tasks
-------
PR: it is the process actual priority, as viewed by the Linux kernel, the scheduling priority of the process. For normal processes, the kernel priority is simply +20 from the nice value. Thus a process with the neutral nice value of zero has a kernel priority of 20. For processes running under real-time, the value of the field is RT

VIRT stands for the virtual size of a process, which is the sum of memory it is actually using, memory it has mapped into itself (for instance the video cardâ€™s RAM for the X server), files on disk that have been mapped into it (most notably shared libraries), and memory shared with other processes. VIRT represents how much memory the program is able to access at the present moment.  The  total  amount  of  virtual  memory  used  by the task.  It
      includes all code, data and shared libraries  plus  pages  that
      have been swapped out.

      VIRT = SWAP + RES.

RES: It is the resident memory size. Resident memory is the amount of non-swapped physical memory a task is using. It stands for the resident size, which is an accurate representation of how much actual physical memory a process is consuming. (This also corresponds directly to the %MEM column.)

SHR: SHR is the shared memory used by the process and it indicates how much of the VIRT size is actually sharable (memory or libraries). In the case of libraries, it does not necessarily mean that the entire library is resident.

TIME+: The total CPU time the task has used since it started, with precision up to hundredth of a second.

COMMAND: The command which was used to start the process

cache is page cache/disk cache in memory
cache for file system I/O, also used as other deviced's cache, e..g, block device
buffer cache is for block device IO -, also memory managed by block

For example, if a process memory-maps a large file, the file is actually stored on disk, but it still takes up "address space" in the process.

load is the avg # of threads in running or un-interruptable
TOP


top -U franshesco

#check the full command that started the process, including location of gc log, jvm configs etc
ps -eaf -p 2973

#sort by %CPU, %MEM to set mem
top -o %CPU

<<CS
note may need to install sysstat
check # of CSs, possible caues
1. normal CS by CPU
2. has higher priority tasks
3. I/O blocking
4. resourse contention and failed to acquire
CS
<<VMSTAT
check context switch times, 10 times, once per second, see if cs >> in. Can use pidstat on top of it
in:interrupt
if si(swap into memory) and so(swap out to harddrive) often > 0, means memory may not be enough
us(user execution time) too high, means user process consumes too much CPU 
wa(IO wait percentable) too high, means IO wait too much
sy(system time- kernel) too high, means IO bottleneck 
r: waiting threads
free: current remaining memory
VMSTAT
vmstat 1 10

<<IOSTAT

Use disk IO latency to decide if disk is under stress
It is best to run iostat specifying a time interval in seconds (for example iostat -x 30)
Display a continuous device report at two second intervals

rrqm/s: The number of read requests merged per second that were queued to the device

rsec/s: The number of sectors read from the device per second.

avgrq-sz:The average size (in sectors) of the requests that were issued to the device., if > 1, often sign device is full

await:The average time (in milliseconds) for I/O requests issued to the device to be served. This includes the time spent by the requests in queue and the time spent servicing them.

if await > svctm, often a sign of long IO queue

iowait in top: wait because of IO, CPU is idle at this time, not a strong indicator itself

%util
Percentage of CPU time during which I/O requests were issued to the device (bandwidth utilization for the device). Device saturation occurs when this value > 60%.

%idle < 70% often a sign of busy IO

IOSTAT
iostat x
iostat -dc 10

###VM Thread often means the GC thread, nid is the OS thread id

#shows the heapsize
java -XX:+PrintFlagsFinal -version | grep HeapSize

top -H -p 63847

# find java processes
ps axu | grep java

# find thread numbers
ps -eLf
# check process parent-child relationship
pstree -p
#check heap usage 
jmap -heap -dump:file=xxx $PID 
#check object number and size
jmap -histo:live pid $PID 

#show java process id or can just ps aux | grep java. Here you can see the importance to giving meaninigful thread name
jps -v 
#jstack -l to show lock info, -m to show native stack
#check current gc status
jstat -gc pid

#view the port associated with a daemon
lsof -i -n -P | grep sendmail

#list open files in the open space
lsof -P -n | wc -l

#show deleted but still referenced files, so use 
lsof | grep deleted
#don't just rm! echo write instead. Otherwise, df still shows referenced file size
echo "" > tomcat.log

#check a port's connectivities
lsof -i:port

###last time  system online
uptime

###who are on this machine
who -a

###uname -a
system version

#under current dir, each dir's space
du -h --max-depth=1

#check a process's memory usage 
pmap $PID

###fio
# slat: how long did it take to submit this IO to the kernel for processing?
# clat: time that passes between submission to the kernel and when the IO is complete, not including submission latency.
# Fio has an iodepth setting that controls how many IOs it issues to the OS at any given time.


# find process taking most CPU
ps H -eo pid,pcpu | sort -nk2 | tail
ll /proc/$PID

# check /var/log/messages for linux OOM killer action, i.e., "killed process"
# for check /var/log/hs_err_pid<pid>.log for jvm fatal erro

# check all process id doing writes
iotop -o

#buffers: buffer cache for block device i/o
#cached: page cache used by FS
# either approaching 0 suggests I/O too high. note that free memory includes the part cache uses. that free is in the context of the application
free -m
