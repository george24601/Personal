td-agent is a stable distribution package of Fluentd. td-agent prioritizes stability over new features

Fluent Bit is a Lightweight Data Forwarder for Fluentd. Fluent Bit is specifically designed for forwarding the data from the edge to Fluentd aggregators.

An event consists of three entities: tag, time and record. The tag is a string separated by ‘.’s (e.g. myapp.access), and is used as the directions for Fluentd’s internal routing engine. The time field is specified by input plugins, and it must be in the Unix time format. The record is a JSON object. 

Set system wide configuration: the “system” directive

Group filter and output: the “label” directive

@ERROR label is a built-in label used for error record emitted by plugin’s emit_error_event API.

If you set <label @ERROR> in the configuration, events are routed to this label when emit related error, e.g. buffer is full or invalid record.

Re-use your config: the “@include” directive

By default, the docker logging driver connects to localhost:24224. Supply the fluentd-address option to connect to a different address. tcp(default) and unix sockets are supported.
in_forward Input plugin listens to a TCP socket to receive the event stream. It also listens to an UDP socket to receive heartbeat messages. Default Value = 24224


Parser
--------
Parse section can be in <source>, <match> or <filter> sections. It’s enabled for plugins which support parser plugin features.

<parse> section requires @type parameter to specify the type of parser plugin. 

List of Core Input Plugins with Parser support
```
in_tail
in_tcp
in_udp
in_syslog
in_http
```

The multiline parser plugin parses multiline logs. This plugin is multiline version of regexp parser.
java stacktrace with multiline parsing
```
format multiline
format_firstline /\d{4}-\d{1,2}-\d{1,2}/
format1 /^(?<time>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2}) \[(?<thread>.*)\] (?<level>[^\s]+)(?<message>.*)/
```

fluent-plugin-concat
-------
<filter **>
  @type concat
  key log
  stream_identity_key container_id
  n_lines 20
  flush_interval 2
#  multiline_start_regexp /^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}.\d{3}
#  multiline_end_regexp /^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}.\d{3}
</filter>


Sample emitted event
----------
2017-09-21T15:03:27Z    tag     {"container_id":"11b0d89723b9c812be65233adbc51a71507bee04e494134258b7af13f089087f","container_name":"/bel_osc.1.bc1k2z6lke1d7djeq5s28xjyl","source":"stdout","log":"2017-09-21 15:03:27.289  INFO 1 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.6"
2017-09-21T15:03:28Z    tag     {"container_id":"11b0d89723b9c812be65233adbc51a71507bee04e494134258b7af13f089087f","container_name":"/bel_osc.1.bc1k2z6lke1d7djeq5s28xjyl","source":"stdout","log":"2017-09-21 15:03:28.191  INFO 1 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext"}`


parser Filter Plugin
----------
in_forward doesn’t provide parsing mechanism unlike in_tail or in_tcp because in_forward is mainly for efficient log transfer. If you want to parse incoming event, use parser filter in your pipeline.

filter_parser has just same with in_tail about format and time_format

<filter foo.bar>
  @type parser
  format /^(?<host>[^ ]*) [^ ]* (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^ ]*) +\S*)?" (?<code>[^ ]*) (?<size>[^ ]*)$/
  time_format %d/%b/%Y:%H:%M:%S %z
  key_name message
</filter>


